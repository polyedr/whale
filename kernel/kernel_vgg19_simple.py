#!/usr/bin/env python
# coding: utf-8

# # Image classification with Keras

# ![](http://)## Install dependencies

# In[ ]:


get_ipython().run_line_magic("matplotlib", "inline")
import os
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from keras import optimizers
from keras.models import Sequential
from keras.layers import (
    Dense,
    Dropout,
    Flatten,
    ZeroPadding2D,
    Conv2D,
    MaxPool2D,
    Activation,
)
from keras.preprocessing.image import ImageDataGenerator

print("import is ready")


# In[ ]:


# set consistent random seed
random_seed = 2018
np.random.seed(random_seed)
tf.set_random_seed(random_seed)


#

# ## Dataset
# Whales dataset

# ### Show the content of the current and parent folder

# In[ ]:


print(os.listdir(".."))
print(os.listdir("."))


# ### Show the content of the input folder

# In[ ]:


print(os.listdir("../input"))


# ### Importing, normalizing, visualizing

# Let's upload whales dataset.

# In[ ]:


# flow_from_dataframe
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c
traindf = pd.read_csv("../input/train.csv", dtype=str)
# remove new whales from input
traindf = traindf[traindf.Id != "new_whale"]
# remove single whales values
traindf = traindf.groupby("Id").filter(lambda x: len(x) > 1)
# plot Id frequencies
traindf["Id"].value_counts()[1:16].plot(kind="bar")

testdf = pd.read_csv("../input/sample_submission.csv", dtype=str)

# datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.5,
    zoom_range=(0.9, 1.1),
    horizontal_flip=False,
    vertical_flip=False,
    fill_mode="constant",
    cval=0,
    rescale=1.0 / 255.0,
    validation_split=0.25,
)


# Print obtained dataframes for checking

# In[ ]:


traindf.shape
# Calculate number of unique classes (whales)
number_of_classes = traindf["Id"].nunique()


# In[ ]:


testdf.head(1)


# In[ ]:


# Pass the dataframes to 2 different flow_from_dataframe functions
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c
train_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory="../input/train/",
    x_col="Image",
    y_col="Id",
    subset="training",
    batch_size=32,
    seed=42,
    shuffle=True,
    class_mode="categorical",
    target_size=(80, 80),
)

valid_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory="../input/train/",
    x_col="Image",
    y_col="Id",
    subset="validation",
    batch_size=32,
    seed=42,
    shuffle=True,
    class_mode="categorical",
    target_size=(80, 80),
)

test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=testdf,
    directory="../input/test/",
    x_col="Image",
    y_col=None,
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode=None,
    target_size=(80, 80),
)


# In[ ]:


# Model @frommedium
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c
model = Sequential()
model.add(Conv2D(64, (3, 3), padding="same", input_shape=(80, 80, 3)))
model.add(Activation("relu"))
model.add(Conv2D(64, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (3, 3), padding="same"))
model.add(Activation("relu"))
model.add(Conv2D(128, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# VGG 19 start
# https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d
# part 2
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(128, (3, 3)))
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(128, (3, 3)))
model.add(MaxPool2D(pool_size=(2, 2)))

# part1
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(256, (3, 3)))
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(256, (3, 3)))
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(256, (3, 3)))
model.add(ZeroPadding2D((1, 1)))
model.add(Conv2D(256, (3, 3)))
model.add(MaxPool2D(pool_size=(2, 2)))

# part3
"""
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(MaxPool2D(pool_size=(2, 2)))

model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(ZeroPadding2D((1,1)))
model.add(Conv2D(512, (3, 3)))
model.add(MaxPool2D(pool_size=(2, 2)))
"""
# VGG 19 end

model.add(Flatten())
# model.add(Dense(512))
model.add(Dense(8192))
model.add(Activation("relu"))
model.add(Dropout(0.5))
model.add(Dense(number_of_classes, activation="softmax"))
model.compile(
    optimizers.rmsprop(lr=0.0001, decay=1e-6),
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)

print("The model is ready")


# In[ ]:


# Fit the model @frommedium
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c
STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size
STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size
STEP_SIZE_TEST = test_generator.n // test_generator.batch_size
# Class weights balancing
history = model.fit_generator(
    generator=train_generator,
    steps_per_epoch=STEP_SIZE_TRAIN,
    validation_data=valid_generator,
    validation_steps=STEP_SIZE_VALID,
    class_weight="auto",
    epochs=9,
)


# In[ ]:


# history plots
plt.plot(history.history["acc"])
plt.title("Model accuracy")
plt.ylabel("accuracy")
plt.xlabel("Epoch")
plt.show()

# Plot the loss curve for training
plt.plot(history.history["loss"], color="r", label="Train Loss")
plt.title("Train Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()


# In[ ]:


# Evaluate model
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c
model.evaluate_generator(generator=valid_generator, steps=1)


# In[ ]:


print(os.listdir("."))


# In[ ]:


# Predict the output
# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c

test_generator.reset()
pred = model.predict_generator(test_generator, steps=STEP_SIZE_TEST + 1, verbose=1)

predicted_class_indices = np.argmax(pred, axis=1)

labels = train_generator.class_indices
labels = dict((v, k) for k, v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]

filenames = test_generator.filenames

print("filenames were prepared")


# In[ ]:


# multiple classes output
# https://www.kaggle.com/hexadd5/simple-resnet50-with-keras
kth = 5
classes = np.array([c for c, v in train_generator.class_indices.items()])

if True:
    classify_index = np.argpartition(-pred, kth)[:, :kth]
    classify_value = pred[np.arange(pred.shape[0])[:, None], classify_index]
    best_5_pred = np.zeros((len(classify_index), 5))
    best_5_class = np.zeros((len(classify_index), 5), dtype="int32")
    for i, p in enumerate(classify_value):
        sort_index = np.argsort(p)[::-1]
        best_5_pred[i] = p[sort_index]
        best_5_class[i] = classify_index[i][sort_index]

    # create output
    submit = pd.DataFrame(columns=["Image", "Id"])
    for i, p in enumerate(best_5_pred):
        submit_classes = []
        if p[0] < 0.55:
            submit_classes.append("new_whale")
            submit_classes.extend(classes[best_5_class[i]][0:4])
        elif p[1] < 0.4:
            submit_classes.extend(classes[best_5_class[i]][0:1])
            submit_classes.append("new_whale")
            submit_classes.extend(classes[best_5_class[i]][1:4])
        elif p[2] < 0.1:
            submit_classes.extend(classes[best_5_class[i]][0:2])
            submit_classes.append("new_whale")
            submit_classes.extend(classes[best_5_class[i]][2:4])
        elif p[3] < 0.05:
            submit_classes.extend(classes[best_5_class[i]][0:3])
            submit_classes.append("new_whale")
            submit_classes.extend(classes[best_5_class[i]][3:4])
        else:
            submit_classes.extend(classes[best_5_class[i]])
        classes_text = " ".join(submit_classes)
        submit = submit.append(
            pd.Series(
                np.array([test_generator.filenames[i], classes_text]),
                index=submit.columns,
            ),
            ignore_index=True,
        )
        # print(submit)
    submit.to_csv("submit.csv", index=False)
    print("submit results were written to the output")


# In[ ]:


print(os.listdir("."))
results = pd.DataFrame({"Filename": filenames})
results_pred = pd.DataFrame({"Predictions": predictions})
results.to_csv("results.csv", index=False)
results_pred.to_csv("results_pred.csv", index=False)
print(os.listdir(".."))
print("results were written to the output")
