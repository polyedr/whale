{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "194274f5-67fc-46f5-a7b4-d1298181ed0e",
    "_uuid": "004920a0c8f7fa0a7b76c84769d703e91414ca29"
   },
   "source": [
    "# Overview\n",
    "With the kernel I am trying to run a simple test on using Siamese networks for similarity on a slightly more complicated problem than standard MNIST.  The idea is to take a randomly initialized network and apply it to images to find out how similar they are. The models should make it much easier to perform tasks like Visual Search on a database of images since it will have a simple similarity metric between 0 and 1 instead of 2D arrays.\n",
    "\n",
    " * [Source Blog Post](http://sujitpal.blogspot.ch/2017/04/predicting-image-similarity-using.html) with this [notebook](https://github.com/sujitpal/holiday-similarity/blob/master/src/02-holidays-siamese-network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "84b0e79e-2070-4000-a76b-8c6f8786117b",
    "_uuid": "7571b744b894ca7d001cf78a7ce17b0939c50eb4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aac47efc-c3f8-4e06-852d-e060fcc7170c",
    "_uuid": "901dc01a65cdec0b544a0bc5f86b6584163ffd7d"
   },
   "source": [
    "# Load and Organize Data\n",
    "Here we load and organize the data so we can easily use it inside of Keras models\n",
    "Creating two arrays, one for the images and one for the labels. I am also resizing the images from 1024x1024 to 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "_cell_guid": "e79131cd-af9f-47bc-8cc0-41539beaad8d",
    "_uuid": "f172fc2cf53f1d2a8abdc355810cde4e0b1aacaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before compilation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-134f175b048d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before compilation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compiled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-134f175b048d>\u001b[0m in \u001b[0;36mproc_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Read and resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mfull_size_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_size_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "# Fashion MNIST dataset. Here are placed values 0..255 for 784 columns which are related to 28 * 28 pixels\n",
    "data_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
    "X_full = data_train.iloc[:,1:]\n",
    "y_full = data_train.iloc[:,:1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.3)\n",
    "\"\"\"\n",
    "# Whales dataset is placed as /train directory, containing raw images together with the file of labels, train.csv\n",
    "# This dataset should be converted to the same shape as fashion dataset example\n",
    "#\n",
    "\n",
    "# Obtain the list of images to train\n",
    "# ../input/\n",
    "PATH = os.path.abspath(os.path.join('..', 'input'))\n",
    "\n",
    "# ../input/sample/images/\n",
    "SOURCE_IMAGES = os.path.join(PATH, \"train\")\n",
    "\n",
    "# ../input/sample/images/*.png\n",
    "images = glob(os.path.join(SOURCE_IMAGES, \"*.jpg\"))\n",
    "\n",
    "# Load labels\n",
    "labels = pd.read_csv('../input/train.csv')\n",
    "# First five images paths\n",
    "images[0:7]\n",
    "\"\"\"\n",
    "# Show five random images\n",
    "r = random.sample(images, 9)\n",
    "#r\n",
    "\n",
    "# Matplotlib black magic\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(231)\n",
    "plt.imshow(cv2.imread(r[0]))\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(cv2.imread(r[1]))\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(cv2.imread(r[2]))  \n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(cv2.imread(r[3]))\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.imshow(cv2.imread(r[4]))\n",
    "\"\"\"\n",
    "\n",
    "# Convertation images into array\n",
    "def proc_images():\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    whale_label=\"new_whale\"\n",
    "\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels Infiltration or Not_infiltration\n",
    "    WIDTH = 28\n",
    "    HEIGHT = 28\n",
    "\n",
    "    for img in images:\n",
    "        base = os.path.basename(img)\n",
    "        #print(base)\n",
    "        finding = labels[\"Id\"][labels[\"Image\"] == base].values[0]\n",
    "\n",
    "        # Read and resize image\n",
    "        full_size_image = cv2.imread(img)\n",
    "        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "        # Labels\n",
    "        if whale_label in finding:\n",
    "            #finding = str(whale_label)\n",
    "            finding = 1\n",
    "            y.append(finding)\n",
    "\n",
    "        else:\n",
    "            #finding = \"Not_\" + str(whale_label)\n",
    "            finding = 0\n",
    "            y.append(finding)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "print(\"before compilation\")\n",
    "x,y = proc_images()\n",
    "print(\"compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[145, 145, 145],\n",
      "        [160, 160, 160],\n",
      "        [162, 162, 162],\n",
      "        ...,\n",
      "        [134, 134, 134],\n",
      "        [118, 118, 118],\n",
      "        [150, 150, 150]],\n",
      "\n",
      "       [[151, 151, 151],\n",
      "        [ 64,  64,  64],\n",
      "        [156, 156, 156],\n",
      "        ...,\n",
      "        [151, 151, 151],\n",
      "        [177, 177, 177],\n",
      "        [172, 172, 172]],\n",
      "\n",
      "       [[101, 101, 101],\n",
      "        [ 98,  98,  98],\n",
      "        [136, 136, 136],\n",
      "        ...,\n",
      "        [127, 127, 127],\n",
      "        [106, 106, 106],\n",
      "        [133, 133, 133]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[161, 161, 161],\n",
      "        [170, 170, 170],\n",
      "        [170, 170, 170],\n",
      "        ...,\n",
      "        [107, 107, 107],\n",
      "        [105, 105, 105],\n",
      "        [113, 113, 113]],\n",
      "\n",
      "       [[137, 137, 137],\n",
      "        [153, 153, 153],\n",
      "        [125, 125, 125],\n",
      "        ...,\n",
      "        [144, 144, 144],\n",
      "        [119, 119, 119],\n",
      "        [134, 134, 134]],\n",
      "\n",
      "       [[120, 120, 120],\n",
      "        [124, 124, 124],\n",
      "        [127, 127, 127],\n",
      "        ...,\n",
      "        [122, 122, 122],\n",
      "        [136, 136, 136],\n",
      "        [103, 103, 103]]], dtype=uint8), array([[[175, 175, 175],\n",
      "        [183, 183, 183],\n",
      "        [207, 207, 207],\n",
      "        ...,\n",
      "        [194, 194, 194],\n",
      "        [173, 173, 173],\n",
      "        [165, 165, 165]],\n",
      "\n",
      "       [[191, 191, 191],\n",
      "        [179, 179, 179],\n",
      "        [223, 223, 223],\n",
      "        ...,\n",
      "        [182, 182, 182],\n",
      "        [197, 197, 197],\n",
      "        [182, 182, 182]],\n",
      "\n",
      "       [[199, 199, 199],\n",
      "        [197, 197, 197],\n",
      "        [192, 192, 192],\n",
      "        ...,\n",
      "        [185, 185, 185],\n",
      "        [174, 174, 174],\n",
      "        [151, 151, 151]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[200, 200, 200],\n",
      "        [205, 205, 205],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [183, 183, 183],\n",
      "        [215, 215, 215],\n",
      "        [211, 211, 211]],\n",
      "\n",
      "       [[174, 174, 174],\n",
      "        [209, 209, 209],\n",
      "        [226, 226, 226],\n",
      "        ...,\n",
      "        [196, 196, 196],\n",
      "        [198, 198, 198],\n",
      "        [178, 178, 178]],\n",
      "\n",
      "       [[198, 198, 198],\n",
      "        [174, 174, 174],\n",
      "        [253, 253, 253],\n",
      "        ...,\n",
      "        [195, 195, 195],\n",
      "        [195, 195, 195],\n",
      "        [204, 204, 204]]], dtype=uint8), array([[[177, 183, 190],\n",
      "        [219, 225, 232],\n",
      "        [203, 210, 219],\n",
      "        ...,\n",
      "        [226, 229, 233],\n",
      "        [223, 226, 231],\n",
      "        [213, 219, 224]],\n",
      "\n",
      "       [[208, 214, 219],\n",
      "        [208, 216, 223],\n",
      "        [211, 219, 226],\n",
      "        ...,\n",
      "        [ 61,  64,  69],\n",
      "        [ 66,  70,  75],\n",
      "        [220, 224, 229]],\n",
      "\n",
      "       [[171, 177, 188],\n",
      "        [182, 191, 196],\n",
      "        [128, 134, 138],\n",
      "        ...,\n",
      "        [218, 221, 226],\n",
      "        [220, 223, 228],\n",
      "        [214, 217, 222]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[136, 141, 149],\n",
      "        [138, 146, 155],\n",
      "        [211, 214, 218],\n",
      "        ...,\n",
      "        [158, 162, 167],\n",
      "        [123, 128, 133],\n",
      "        [199, 203, 208]],\n",
      "\n",
      "       [[100, 107, 116],\n",
      "        [129, 135, 142],\n",
      "        [145, 151, 158],\n",
      "        ...,\n",
      "        [ 61,  66,  69],\n",
      "        [ 75,  78,  83],\n",
      "        [ 59,  66,  69]],\n",
      "\n",
      "       [[156, 160, 165],\n",
      "        [136, 140, 145],\n",
      "        [129, 132, 137],\n",
      "        ...,\n",
      "        [ 45,  50,  53],\n",
      "        [ 95,  99, 104],\n",
      "        [104, 107, 112]]], dtype=uint8), array([[[143, 113,  88],\n",
      "        [ 67,  59,  59],\n",
      "        [163, 127, 103],\n",
      "        ...,\n",
      "        [122, 102,  85],\n",
      "        [103,  89,  67],\n",
      "        [142, 108,  85]],\n",
      "\n",
      "       [[184, 143, 111],\n",
      "        [162, 126, 100],\n",
      "        [165, 127,  97],\n",
      "        ...,\n",
      "        [174, 130, 106],\n",
      "        [174, 130, 106],\n",
      "        [198, 154, 125]],\n",
      "\n",
      "       [[165, 130, 104],\n",
      "        [173, 138, 108],\n",
      "        [160, 127,  99],\n",
      "        ...,\n",
      "        [161, 120,  95],\n",
      "        [164, 124,  94],\n",
      "        [163, 123,  95]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[125, 100,  80],\n",
      "        [ 73,  49,  37],\n",
      "        [ 52,  41,  37],\n",
      "        ...,\n",
      "        [155, 137, 150],\n",
      "        [136, 111, 126],\n",
      "        [137, 104, 108]],\n",
      "\n",
      "       [[180, 147, 126],\n",
      "        [ 53,  37,  31],\n",
      "        [ 74,  62,  62],\n",
      "        ...,\n",
      "        [135, 100,  88],\n",
      "        [164, 137, 124],\n",
      "        [150, 132, 115]],\n",
      "\n",
      "       [[176, 143, 137],\n",
      "        [ 43,  29,  28],\n",
      "        [163, 135, 131],\n",
      "        ...,\n",
      "        [139, 105, 115],\n",
      "        [120,  99,  90],\n",
      "        [158, 142, 126]]], dtype=uint8), array([[[189, 188, 178],\n",
      "        [180, 179, 169],\n",
      "        [195, 193, 185],\n",
      "        ...,\n",
      "        [184, 182, 172],\n",
      "        [180, 177, 169],\n",
      "        [172, 172, 160]],\n",
      "\n",
      "       [[175, 174, 164],\n",
      "        [180, 181, 177],\n",
      "        [181, 179, 170],\n",
      "        ...,\n",
      "        [194, 192, 184],\n",
      "        [192, 188, 182],\n",
      "        [190, 188, 180]],\n",
      "\n",
      "       [[178, 177, 170],\n",
      "        [124, 126, 124],\n",
      "        [ 96, 100,  97],\n",
      "        ...,\n",
      "        [186, 184, 176],\n",
      "        [195, 191, 186],\n",
      "        [191, 188, 180]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[121, 119,  99],\n",
      "        [209, 206, 201],\n",
      "        [155, 155, 145],\n",
      "        ...,\n",
      "        [162, 158, 147],\n",
      "        [184, 177, 168],\n",
      "        [197, 193, 182]],\n",
      "\n",
      "       [[130, 129, 114],\n",
      "        [150, 150, 135],\n",
      "        [147, 145, 130],\n",
      "        ...,\n",
      "        [111, 112,  85],\n",
      "        [ 88,  90,  60],\n",
      "        [205, 201, 200]],\n",
      "\n",
      "       [[178, 176, 165],\n",
      "        [179, 174, 165],\n",
      "        [183, 178, 169],\n",
      "        ...,\n",
      "        [117, 118,  92],\n",
      "        [130, 126, 106],\n",
      "        [170, 165, 150]]], dtype=uint8)]\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(x[0:5])\n",
    "#print(x.shape)\n",
    "print(y[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Splitting \n",
    "# X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=0.2, random_state=33)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "#print(x_train[0], x_test[0], y_train[0], y_test[0])\n",
    "\n",
    "# Data should be placed to numpy arrays, and not in lists\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "print(type(x_train), type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "_cell_guid": "715029d1-dbb0-4b4f-b561-2940af7c6b8b",
    "_uuid": "a9ef1b7565b452a157780333b349e9aa238e2a9d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-02d9a2ad51c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "x_train = x_train.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "# x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "\"\"\"\n",
    "x_train = x_train.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "x_test = x_test.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "y_train = y_train.values.astype('int')\n",
    "y_test = y_test.values.astype('int')\n",
    "print('Training', x_train.shape, x_train.max())\n",
    "print('Testing', x_test.shape, x_test.max())\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Test for MNIST\n",
    "data_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
    "X_full = data_train.iloc[:,1:]\n",
    "y_full = data_train.iloc[:,:1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.3)\n",
    "print(type(x_train), type(X_full))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8d657e3-188b-4e54-983d-d15d4b3bab35",
    "_uuid": "1a9921746a6218acb06843fafd0d6b5295f632af"
   },
   "outputs": [],
   "source": [
    "# reorganize by groups\n",
    "train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)]\n",
    "test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)]\n",
    "print('train groups:', [x.shape[0] for x in train_groups])\n",
    "print('test groups:', [x.shape[0] for x in test_groups])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f808e85d-a06f-46fd-bfa5-3abdd1891ac6",
    "_uuid": "f5e65ee27028b8a12dc0262b6dda46fc961da960"
   },
   "source": [
    "### Batch Generation\n",
    "Here the idea is to make usuable batches for training the network. We need to create parallel inputs for the $A$ and $B$ images where the output is the distance. Here we make the naive assumption that if images are in the same group the similarity is 1 otherwise it is 0.\n",
    "\n",
    "If we randomly selected all of the images we would likely end up with most images in different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "92363237-06a8-45fb-8fee-ca3cbfceee28",
    "_uuid": "be862af7ac7aed4d0750901f7607f99fa13ccd9f"
   },
   "outputs": [],
   "source": [
    "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
    "    out_img_a, out_img_b, out_score = [], [], []\n",
    "    all_groups = list(range(len(in_groups)))\n",
    "    for match_group in [True, False]:\n",
    "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
    "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
    "        if match_group:\n",
    "            b_group_idx = group_idx\n",
    "            out_score += [1]*batch_halfsize\n",
    "        else:\n",
    "            # anything but the same group\n",
    "            non_group_idx = [np.random.choice([i for i in all_groups if i!=c_idx]) for c_idx in group_idx] \n",
    "            b_group_idx = non_group_idx\n",
    "            out_score += [0]*batch_halfsize\n",
    "            \n",
    "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
    "            \n",
    "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "371eb798-eb9c-4318-a85e-99a437f13e9e",
    "_uuid": "9b7bea9e57008ba6d744e659cee7edaeecf63dcc"
   },
   "source": [
    "## Validate Data\n",
    "Here we make sure the generator is doing something sensible, we show the images and their similarity percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "724c5b9c-146e-4473-8a76-c9e71a3e461e",
    "_uuid": "59fcb14fe3e2dabc3891c77ab9c68f83bb0f8e90"
   },
   "outputs": [],
   "source": [
    "pv_a, pv_b, pv_sim = gen_random_batch(train_groups, 3)\n",
    "fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "for c_a, c_b, c_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, m_axs.T):\n",
    "    ax1.imshow(c_a[:,:,0])\n",
    "    ax1.set_title('Image A')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(c_b[:,:,0])\n",
    "    ax2.set_title('Image B\\n Similarity: %3.0f%%' % (100*c_d))\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ad59d9a-ed49-42bf-81c6-6c13801a6ba1",
    "_uuid": "d07aca571e287b5f7fa8a71c7f70cb6f62441b1e"
   },
   "source": [
    "# Feature Generation\n",
    "Here we make the feature generation network to process images into features. The network starts off randomly initialized and will be trained to generate useful vector features from input images (_hopefully_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6ed64c0-ad8b-40d8-a5a0-b2c5a99ea460",
    "_uuid": "be64ceda9605e1dd493fe2b429172111a422bcf3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout\n",
    "img_in = Input(shape = x_train.shape[1:], name = 'FeatureNet_ImageInput')\n",
    "n_layer = img_in\n",
    "for i in range(2):\n",
    "    n_layer = Conv2D(8*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
    "    n_layer = BatchNormalization()(n_layer)\n",
    "    n_layer = Activation('relu')(n_layer)\n",
    "    n_layer = Conv2D(16*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
    "    n_layer = BatchNormalization()(n_layer)\n",
    "    n_layer = Activation('relu')(n_layer)\n",
    "    n_layer = MaxPool2D((2,2))(n_layer)\n",
    "n_layer = Flatten()(n_layer)\n",
    "n_layer = Dense(32, activation = 'linear')(n_layer)\n",
    "n_layer = Dropout(0.5)(n_layer)\n",
    "n_layer = BatchNormalization()(n_layer)\n",
    "n_layer = Activation('relu')(n_layer)\n",
    "feature_model = Model(inputs = [img_in], outputs = [n_layer], name = 'FeatureGenerationModel')\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8acfa1dc-9077-4fc9-8b6d-564f6a30729b",
    "_uuid": "8f84b5cf735c25b94286fc8f56b9ab45f36d3ba1"
   },
   "source": [
    "# Siamese Model\n",
    "We apply the feature generating model to both images and then combine them together to predict if they are similar or not. The model is designed to very simple. The ultimate idea is when a new image is taken that a feature vector can be calculated for it using the _FeatureGenerationModel_. All existing images have been pre-calculated and stored in a database of feature vectors. The model can be applied using a few vector additions and multiplications to determine the most similar images. These operations can be implemented as a stored procedure or similar task inside the database itself since they do not require an entire deep learning framework to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dc5ea3d4-1d80-4cca-8e7b-d1c58dd458a7",
    "_uuid": "c5ddc93960b88d6a983a18e1a1c807314ad150b9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "img_a_in = Input(shape = x_train.shape[1:], name = 'ImageA_Input')\n",
    "img_b_in = Input(shape = x_train.shape[1:], name = 'ImageB_Input')\n",
    "img_a_feat = feature_model(img_a_in)\n",
    "img_b_feat = feature_model(img_b_in)\n",
    "combined_features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
    "combined_features = Dense(16, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(4, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = Model(inputs = [img_a_in, img_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a479eeb-bfa2-4a17-9e4d-154799d0300d",
    "_uuid": "bf91b28c1dac2b28f34569e9b3ca856d1152f4a9"
   },
   "outputs": [],
   "source": [
    "# setup the optimization process\n",
    "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Model Feedback\n",
    "Here we visualize what the model does by taking a small sample of randomly selected A and B images the first half from the same category and the second from different categories. We then show the actual distance (0 for the same category and 1 for different categories) as well as the model predicted distance. The first run here is with a completely untrained network so we do not expect meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_output(nb_examples = 3):\n",
    "    pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)\n",
    "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
    "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
    "        ax1.imshow(c_a[:,:,0])\n",
    "        ax1.set_title('Image A\\n Actual: %3.0f%%' % (100*c_d))\n",
    "        ax1.axis('off')\n",
    "        ax2.imshow(c_b[:,:,0])\n",
    "        ax2.set_title('Image B\\n Predicted: %3.0f%%' % (100*p_d))\n",
    "        ax2.axis('off')\n",
    "    return fig\n",
    "# a completely untrained model\n",
    "_ = show_model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e2f2557-63c3-4c35-83bf-bd38351e1867",
    "_uuid": "7dbe0850a234b0763f9f00eb6949588af1e899bb"
   },
   "outputs": [],
   "source": [
    "# make a generator out of the data\n",
    "def siam_gen(in_groups, batch_size = 32):\n",
    "    while True:\n",
    "        pv_a, pv_b, pv_sim = gen_random_batch(train_groups, batch_size//2)\n",
    "        yield [pv_a, pv_b], pv_sim\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024)\n",
    "loss_history = similarity_model.fit_generator(siam_gen(train_groups), \n",
    "                               steps_per_epoch = 500,\n",
    "                               validation_data=([valid_a, valid_b], valid_sim),\n",
    "                                              epochs = 10,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40b32060-c873-4f29-bd3a-65a7dc64f88e",
    "_uuid": "8f7b141665f09e06954f50583f43481e34c1e66a"
   },
   "outputs": [],
   "source": [
    "_ = show_model_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Shirt vs Ankle Boot-Plot\n",
    "Here we take an random t-shirt and ankle boot (categories 0 and 9) images and calculate the distance using our network to the other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirt_vec = np.stack([train_groups[0][0]]*x_test.shape[0],0)\n",
    "t_shirt_score = similarity_model.predict([t_shirt_vec, x_test], verbose = True, batch_size = 128)\n",
    "ankle_boot_vec = np.stack([train_groups[-1][0]]*x_test.shape[0],0)\n",
    "ankle_boot_score = similarity_model.predict([ankle_boot_vec, x_test], verbose = True, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_categories = ['T-shirt/top','Trouser','Pullover','Dress',\n",
    "                  'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
    "                 ]\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
    "    plt.scatter(t_shirt_score[np.where(y_test == c_group), 0],\n",
    "                ankle_boot_score[np.where(y_test == c_group), 0],\n",
    "                marker='.',\n",
    "                color=c_color,\n",
    "                linewidth='1',\n",
    "                alpha=0.8,\n",
    "                label=c_label)\n",
    "plt.xlabel('T-Shirt Dimension')\n",
    "plt.ylabel('Ankle-Boot Dimension')\n",
    "plt.title('T-Shirt and Ankle-Boot Dimension')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('tshirt-boot-dist.png')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fbf9e442-4604-4a4d-b8b5-9d30cb99299e",
    "_uuid": "37934c83ab75a0930e1f6ec1e5dc1303e29869c3",
    "collapsed": true
   },
   "source": [
    "## Examining the Features\n",
    "Here we aim to answer the more general question: did we generate useful features with the Feature Generation model? And how can we visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6fba813-fcec-427d-a69a-f99f574c846b",
    "_uuid": "1639aebf47636318e0ab22ad206fbe538e758338"
   },
   "outputs": [],
   "source": [
    "x_test_features = feature_model.predict(x_test, verbose = True, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor Visualization\n",
    "For this we use the TSNE neighborhood embedding to visualize the features on a 2D plane and see if it roughly corresponds to the groups. We use the test data for this example as well since the training has been contaminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e851958f-df6f-4efe-9653-da2a5b6251ca",
    "_uuid": "7adba53e5b837d6efca4d022067d2c7c3a8109ba",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "tsne_obj = TSNE(n_components=2,\n",
    "                         init='pca',\n",
    "                         random_state=101,\n",
    "                         method='barnes_hut',\n",
    "                         n_iter=500,\n",
    "                         verbose=2)\n",
    "tsne_features = tsne_obj.fit_transform(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1681b97-5607-4051-a8d1-efbe2a4c1ad8",
    "_uuid": "26ea6aec333510280b143c870bc37e3fc4263b84"
   },
   "outputs": [],
   "source": [
    "obj_categories = ['T-shirt/top','Trouser','Pullover','Dress',\n",
    "                  'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
    "                 ]\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
    "    plt.scatter(tsne_features[np.where(y_test == c_group), 0],\n",
    "                tsne_features[np.where(y_test == c_group), 1],\n",
    "                marker='o',\n",
    "                color=c_color,\n",
    "                linewidth='1',\n",
    "                alpha=0.8,\n",
    "                label=c_label)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('t-SNE on Testing Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('clothes-dist.png')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5363761-e430-4931-850e-c969bc7e4310",
    "_uuid": "2d30521ad626f9f6b5492f1a10a4bef6e276a0b3"
   },
   "outputs": [],
   "source": [
    "feature_model.save('fashion_feature_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ef2bc89-e47d-4260-b2d9-8fa5177921ca",
    "_uuid": "8a98c77220863cd966a0f720aa06a7ca64567b2f"
   },
   "outputs": [],
   "source": [
    "similarity_model.save('fashion_similarity_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
